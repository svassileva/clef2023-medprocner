{"cells":[{"cell_type":"markdown","metadata":{"id":"X4cRE8IbIrIV"},"source":["If you're opening this Notebook on colab, you will probably need to install ü§ó Transformers and ü§ó Datasets. Uncomment the following cell and run it."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOsHUjgdIrIW","outputId":"18879962-5d59-47a9-cea4-35eab0476bc3","executionInfo":{"status":"ok","timestamp":1681483188213,"user_tz":-180,"elapsed":24800,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.2.2)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=49bf498b802e12165592db0cc02cb5e9336ad842ffb98bc2fe610fcbc8a37f64\n","  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n","Successfully built seqeval\n","Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, seqeval, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.4 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 seqeval-1.2.2 tokenizers-0.13.3 transformers-4.28.0 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["! pip install datasets transformers seqeval"]},{"cell_type":"markdown","metadata":{"id":"U1KmKwdp0U2y"},"source":["If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n","\n","To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n","\n","First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec29xXps0U2y"},"outputs":[],"source":["#from huggingface_hub import notebook_login\n","\n","#notebook_login()"]},{"cell_type":"markdown","metadata":{"id":"y_bkObAU0U2z"},"source":["Then you need to install Git-LFS. Uncomment the following instructions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe2DZcab0U2z"},"outputs":[],"source":["# !apt install git-lfs"]},{"cell_type":"markdown","metadata":{"id":"gGWbb7cj0U2z"},"source":["Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eC6oJCSh0U20","executionInfo":{"status":"ok","timestamp":1681483188214,"user_tz":-180,"elapsed":9,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"054e5de1-3853-4a46-c323-1364718eb54f"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.28.0\n"]}],"source":["import transformers\n","\n","print(transformers.__version__)"]},{"cell_type":"markdown","metadata":{"id":"HFASsisvIrIb"},"source":["You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/token-classification)."]},{"cell_type":"markdown","metadata":{"id":"x-zJPOnN0U21"},"source":["We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YC3KptPt0U22"},"outputs":[],"source":["#from transformers.utils import send_example_telemetry\n","\n","#send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"]},{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["# Fine-tuning a model on a token classification task"]},{"cell_type":"markdown","metadata":{"id":"68ZSiKA60U23"},"source":["In this notebook, we will see how to fine-tune one of the [ü§ó Transformers](https://github.com/huggingface/transformers) model to a token classification task, which is the task of predicting a label for each token.\n","\n","![Widget inference representing the NER task](images/token_classification.png)\n","\n","The most common token classification tasks are:\n","\n","- NER (Named-entity recognition) Classify the entities in the text (person, organization, location...).\n","- POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...)\n","- Chunk (Chunking) Grammatically classify the tokens and group them into \"chunks\" that go together\n","\n","We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it."]},{"cell_type":"markdown","metadata":{"id":"4RRkXuteIrIh"},"source":["This notebook is built to run on any token classification task, with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVvslsfMIrIh"},"outputs":[],"source":["task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n","model_checkpoint = \"PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\" #\"PlanTL-GOB-ES/bsc-bio-ehr-es\"\n","batch_size = 16"]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"markdown","metadata":{"id":"W7QYTpxXIrIl"},"source":["We will use the [ü§ó Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IreSlFmlIrIm"},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrqigytQ0tH-","executionInfo":{"status":"ok","timestamp":1681483305758,"user_tz":-180,"elapsed":117005,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"b39ef851-2806-48d9-8231-dfe9d91946ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"CKx2zKs5IrIq"},"source":["For our example here, we'll use the [CONLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf). The notebook should work with any token classification dataset provided by the ü§ó Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["78f159aaca6948d69754a235073a72b6","e8af60fc134747379018da09a1b664ee","f086696d3ee6486f824bb618c7133056","194854063f9c453589869749e6c2f570","775d99d923fa4cef8f0d6626d93c6ca1","81431a2622504d76b009f64b1b3a1bf7","77abf11b516744db880dd1af91146886","fb66d823f24d45f6a9ac521783c3423d","e863f49462174ae4a042c9106edf6a98","c9479b978329462aab901b7ca2047236","cf54f2e3b5f341dc9d0322d222552749","d9416fd8213e4806821bc9affd7bd3a4","217b509357aa4bba8a61760c0fa0a64a","f338acf4e6be4e0d8664c62a95c7013f","822bbc33d7ba407eb398c3274f7f6707","3e3eb094581b437895ed6edd4f32059f","f8851ad367b84f47911e9cf2507a26ec","95ec96bedbf94a28997193b56c73750e","9f1a8e0e98044f9fa135bff1f014f395","d02f3d852ae24b08ae15040e4417de5a","05e5837ee6f54b1da2fd1438efd78269","b2ed932423324294af65b6ac7d0372e8"]},"id":"s_AY1ATSIrIq","outputId":"23c2d045-7ee8-4373-97fb-1f448d9c3f4f","executionInfo":{"status":"ok","timestamp":1681483311249,"user_tz":-180,"elapsed":5499,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset custom_dataset/customconll2003 to /root/.cache/huggingface/datasets/custom_dataset/customconll2003/1.0.0/5c1a1699f8c949ed42bb8da4620f3179206b04e5d13ccc3d5b20ebb72744bd52...\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78f159aaca6948d69754a235073a72b6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset custom_dataset downloaded and prepared to /root/.cache/huggingface/datasets/custom_dataset/customconll2003/1.0.0/5c1a1699f8c949ed42bb8da4620f3179206b04e5d13ccc3d5b20ebb72744bd52. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9416fd8213e4806821bc9affd7bd3a4"}},"metadata":{}}],"source":["#datasets = load_dataset(\"conll2003\")\n","#datasets = load_dataset(\"/content/drive/MyDrive/CLEF2023/custom_dataset\")\n","from datasets import DatasetDict\n","\n","dataset_split = load_dataset('/content/drive/MyDrive/CLEF2023/custom_dataset', split=[\n","    'train[0%:90%]', 'train[90%:100%]'\n","])\n","\n","datasets = DatasetDict({'train': dataset_split[0], 'validation': dataset_split[1]})"]},{"cell_type":"markdown","metadata":{"id":"RzfPtOMoIrIu"},"source":["The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWiVUF0jIrIv","outputId":"fba1831d-147a-4b8f-d307-c6ef52e45ef7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681483311249,"user_tz":-180,"elapsed":20,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 674\n","    })\n","    validation: Dataset({\n","        features: ['id', 'tokens', 'ner_tags'],\n","        num_rows: 75\n","    })\n","})"]},"metadata":{},"execution_count":10}],"source":["datasets"]},{"cell_type":"markdown","metadata":{"id":"qvCAXkkp0U27"},"source":["We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before."]},{"cell_type":"markdown","metadata":{"id":"u3EtYfeHIrIz"},"source":["To access an actual element, you need to select a split first, then give an index:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6HrpprwIrIz","outputId":"9f421a51-3ce2-4f5d-cc37-54d96c7bd8c7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681483311250,"user_tz":-180,"elapsed":19,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '0',\n"," 'tokens': ['Paciente',\n","  'de',\n","  '70',\n","  'a√±os',\n","  'de',\n","  'edad,',\n","  'minero',\n","  'jubilado,',\n","  'sin',\n","  'alergias',\n","  'medicamentosas',\n","  'conocidas,',\n","  'que',\n","  'presenta',\n","  'como',\n","  'antecedentes',\n","  'personales:',\n","  'accidente',\n","  'laboral',\n","  'antiguo',\n","  'con',\n","  'fracturas',\n","  'vertebrales',\n","  'y',\n","  'costales;',\n","  'intervenido',\n","  'de',\n","  'enfermedad',\n","  'de',\n","  'Dupuytren',\n","  'en',\n","  'mano',\n","  'derecha',\n","  'y',\n","  'by-pass',\n","  'iliofemoral',\n","  'izquierdo;',\n","  'Diabetes',\n","  'Mellitus',\n","  'tipo',\n","  'II,',\n","  'hipercolesterolemia',\n","  'e',\n","  'hiperuricemia;',\n","  'enolismo',\n","  'activo,',\n","  'fumador',\n","  'de',\n","  '20',\n","  'cigarrillos',\n","  '/',\n","  'd√≠a.',\n","  'Es',\n","  'derivado',\n","  'desde',\n","  'Atenci√≥n',\n","  'Primaria',\n","  'por',\n","  'presentar',\n","  'hematuria',\n","  'macrosc√≥pica',\n","  'postmiccional',\n","  'en',\n","  'una',\n","  'ocasi√≥n',\n","  'y',\n","  'microhematuria',\n","  'persistente',\n","  'posteriormente,',\n","  'con',\n","  'micciones',\n","  'normales.',\n","  'En',\n","  'la',\n","  'exploraci√≥n',\n","  'f√≠sica',\n","  'presenta',\n","  'un',\n","  'buen',\n","  'estado',\n","  'general,',\n","  'con',\n","  'abdomen',\n","  'y',\n","  'genitales',\n","  'normales;',\n","  'tacto',\n","  'rectal',\n","  'compatible',\n","  'con',\n","  'adenoma',\n","  'de',\n","  'pr√≥stata',\n","  'grado',\n","  'I/IV.',\n","  'En',\n","  'la',\n","  'anal√≠tica',\n","  'de',\n","  'orina',\n","  'destaca',\n","  'la',\n","  'existencia',\n","  'de',\n","  '4',\n","  'hemat√≠es/',\n","  'campo',\n","  'y',\n","  '0-5',\n","  'leucocitos/campo;',\n","  'resto',\n","  'de',\n","  'sedimento',\n","  'normal.',\n","  'Hemograma',\n","  'normal;',\n","  'en',\n","  'la',\n","  'bioqu√≠mica',\n","  'destaca',\n","  'una',\n","  'glucemia',\n","  'de',\n","  '169',\n","  'mg/dl',\n","  'y',\n","  'triglic√©ridos',\n","  'de',\n","  '456',\n","  'mg/dl;',\n","  'funci√≥n',\n","  'hep√°tica',\n","  'y',\n","  'renal',\n","  'normal.',\n","  'PSA',\n","  'de',\n","  '1.16',\n","  'ng/ml.',\n","  'Las',\n","  'citolog√≠as',\n","  'de',\n","  'orina',\n","  'son',\n","  'repetidamente',\n","  'sospechosas',\n","  'de',\n","  'malignidad.',\n","  'En',\n","  'la',\n","  'placa',\n","  'simple',\n","  'de',\n","  'abdomen',\n","  'se',\n","  'valoran',\n","  'cambios',\n","  'degenerativos',\n","  'en',\n","  'columna',\n","  'lumbar',\n","  'y',\n","  'calcificaciones',\n","  'vasculares',\n","  'en',\n","  'ambos',\n","  'hipocondrios',\n","  'y',\n","  'en',\n","  'pelvis.',\n","  'La',\n","  'ecograf√≠a',\n","  'urol√≥gica',\n","  'pone',\n","  'de',\n","  'manifiesto',\n","  'la',\n","  'existencia',\n","  'de',\n","  'quistes',\n","  'corticales',\n","  'simples',\n","  'en',\n","  'ri√±√≥n',\n","  'derecho,',\n","  'vejiga',\n","  'sin',\n","  'alteraciones',\n","  'con',\n","  'buena',\n","  'capacidad',\n","  'y',\n","  'pr√≥stata',\n","  'con',\n","  'un',\n","  'peso',\n","  'de',\n","  '30',\n","  'g.',\n","  'En',\n","  'la',\n","  'UIV',\n","  'se',\n","  'observa',\n","  'normofuncionalismo',\n","  'renal',\n","  'bilateral,',\n","  'calcificaciones',\n","  'sobre',\n","  'silueta',\n","  'renal',\n","  'derecha',\n","  'y',\n","  'ur√©teres',\n","  'arrosariados',\n","  'con',\n","  'im√°genes',\n","  'de',\n","  'adici√≥n',\n","  'en',\n","  'el',\n","  'tercio',\n","  'superior',\n","  'de',\n","  'ambos',\n","  'ur√©teres,',\n","  'en',\n","  'relaci√≥n',\n","  'a',\n","  'pseudodiverticulosis',\n","  'ureteral.',\n","  'El',\n","  'cistograma',\n","  'demuestra',\n","  'una',\n","  'vejiga',\n","  'con',\n","  'buena',\n","  'capacidad,',\n","  'pero',\n","  'paredes',\n","  'trabeculadas',\n","  'en',\n","  'relaci√≥n',\n","  'a',\n","  'vejiga',\n","  'de',\n","  'esfuerzo.',\n","  'La',\n","  'TC',\n","  'abdominal',\n","  'es',\n","  'normal.',\n","  'La',\n","  'cistoscopia',\n","  'descubre',\n","  'la',\n","  'existencia',\n","  'de',\n","  'peque√±as',\n","  'tumoraciones',\n","  'vesicales,',\n","  'realiz√°ndose',\n","  'resecci√≥n',\n","  'transuretral',\n","  'con',\n","  'el',\n","  'resultado',\n","  'anatomopatol√≥gico',\n","  'de',\n","  'carcinoma',\n","  'urotelial',\n","  'superficial',\n","  'de',\n","  'vejiga.'],\n"," 'ner_tags': [0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  0,\n","  1,\n","  0,\n","  0,\n","  0,\n","  1,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  2,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  2,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  1,\n","  2,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"metadata":{},"execution_count":11}],"source":["datasets[\"train\"][0]"]},{"cell_type":"markdown","metadata":{"id":"lJWMrdCF0U27"},"source":["The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the `features` of the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndi9T-ba0U28","executionInfo":{"status":"ok","timestamp":1681483311251,"user_tz":-180,"elapsed":17,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"55a718dc-5205-4f2a-f41a-6bf7ec914516"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequence(feature=ClassLabel(names=['O', 'B-PROCEDIMIENTO', 'I-PROCEDIMIENTO'], id=None), length=-1, id=None)"]},"metadata":{},"execution_count":12}],"source":["datasets[\"train\"].features[f\"ner_tags\"]"]},{"cell_type":"markdown","metadata":{"id":"wgs8RgeP0U28"},"source":["So for the NER tags, 0 corresponds to 'O', 1 to 'B-PER' etc... On top of the 'O' (which means no special entity), there are four labels for NER here, each prefixed with 'B-' (for beginning) or 'I-' (for intermediate), that indicate if the token is the first one for the current group with the label or not:\n","- 'PER' for person\n","- 'ORG' for organization\n","- 'LOC' for location\n","- 'MISC' for miscellaneous"]},{"cell_type":"markdown","metadata":{"id":"4x9EraBX0U2-"},"source":["Since the labels are lists of `ClassLabel`, the actual names of the labels are nested in the `feature` attribute of the object above:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjKQ_I8K0U2-","executionInfo":{"status":"ok","timestamp":1681483311251,"user_tz":-180,"elapsed":9,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"81d156a0-0b97-4414-ea31-3d81f4954a96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O', 'B-PROCEDIMIENTO', 'I-PROCEDIMIENTO']"]},"metadata":{},"execution_count":13}],"source":["label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n","label_list"]},{"cell_type":"markdown","metadata":{"id":"WHUmphG3IrI3"},"source":["To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3j8APAoIrI3"},"outputs":[],"source":["from datasets import ClassLabel, Sequence\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","def show_random_elements(dataset, num_examples=10):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n","            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n","    display(HTML(df.to_html()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZy5tRB_IrI7","outputId":"a03f31d7-a264-4af9-c384-2d569918f4d1","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1681483311252,"user_tz":-180,"elapsed":8,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tokens</th>\n","      <th>ner_tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>583</td>\n","      <td>[Var√≥n, de, 45, a√±os, de, edad,, sin, alergias, medicamentosas, conocidas., Entre, sus, antecedentes, personales:, exfumador, (m√°s, de, 30, paquetes/a√±o),, diabetes, mellitus, tipo, 2,, hipercolesterolemia,, una, historia, de, anticuerpo, antifosfol√≠pido, circulante, con, antecedentes, de, dos, trombosis, venosas, profundas., Dentro, de, su, historia, vascular, previa, al, ingreso:, en, octubre, del, 2004, se, le, hab√≠a, colocado, un, stent, il√≠aco, izquierdo, m√°s, un, by-pass, f√©moro-femoral, izquierda-derecha., En, febrero, del, 2005, se, le, realiz√≥, dilataci√≥n, con, crioterapia, de, il√≠aca, izquierda,, que, no, es, efectiva, por, lo, que, se, le, realiza, by-pass, f√©moro-popl√≠teo, a, primera, porci√≥n, en, el, miembro, inferior, izquierdo., En, febrero, del, 2006, ingresa, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>312</td>\n","      <td>[Mujer, de, 45, a√±os, que, es, remitida, desde, el, servicio, de, neurocirug√≠a, por, p√©rdida, de, visi√≥n, s√∫bita, bilateral, tras, cirug√≠a, de, derivaci√≥n, ventr√≠culoperitoneal, de, un, higroma, subdural, temporal, y, absceso, occipital, craneal., Todo, ello, resultado, de, una, complicaci√≥n, postquir√∫rgica, subaguda., Quince, d√≠as, antes, hab√≠a, sido, intervenida, de, descompresi√≥n, preventiva, medular, por, Malformaci√≥n, de, Arnold-Chiari, I., La, paciente, contaba, con, una, cl√≠nica, de, 16, a√±os, de, evoluci√≥n,, con, cefaleas, de, intensidad, leve,, inestabilidad,, mareos, rotatorios,, v√≥mitos, autolimitados, de, duraci√≥n, variable, y, nistagmus, vertical, leve, desde, hac√≠a, un, a√±o., √âste, √∫ltimo, ayud√≥, a, la, sospecha, y, diagn√≥stico, de, la, malformaci√≥n, cong√©nita,, ya, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>235</td>\n","      <td>[Var√≥n, de, 51, a√±os, con, enfermedad, de, Crohn, ileoc√≥lica, de, larga, evoluci√≥n,, con, m√∫ltiples, complicaciones, por, brotes, y, que, precis√≥, cirug√≠a, de, resecci√≥n, intestinal, quedando, con, una, ileostom√≠a, terminal, en, 2009., Este, a√±o, se, inicia, NPD, mediante, un, dispositivo, intravascular, totalmente, implantado., Se, encontraba, en, tratamiento, con, Infliximab, y, corticoides., El, a√±o, siguiente, ingresa, en, varias, ocasiones, por, s√≠ndrome, febril, asociado, a, dolor, abdominal,, sin, un, foco, evidente, y, consider√°ndose, el, origen, la, propia, enfermedad., En, tales, hospitalizaciones, se, aisl√≥, Staphylococcus, epidermidis, en, varios, hemocultivos., Tambi√©n, se, sustituy√≥, el, cat√©ter, por, rotura,, retir√°ndose, solamente, el, reservorio, y, la, porci√≥n, proximal, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, B-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>642</td>\n","      <td>[Presentamos, el, caso, de, una, ni√±a, de, 4, a√±os, que, consult√≥, por, un, exantema, eritr√≥sico, y, doloroso, en, regi√≥n, cervical, de, 12, horas, de, evoluci√≥n., La, paciente, ten√≠a, malestar, general,, no, presentaba, fiebre,, s√≠ntomas, respiratorios, ni, otros, s√≠ntomas, a√±adidos., Hab√≠a, sido, valorada, hac√≠a, 6, horas, como, un, posible, pr√∫rigo,, habiendo, iniciado, tratamiento, con, corticoide, y, antihistam√≠nico, por, v√≠a, sist√©mica., A, la, exploraci√≥n, f√≠sica, presentaba, eritema, cut√°neo, en, cuello,, axilas,, t√≥rax, y, nalgas,, con, √°reas, de, despegamiento, cut√°neo, en, zona, axilar, y, cervical, y, alguna, lesi√≥n, costrosa, amarillenta, en, regi√≥n, cervical., Tambi√©n, mostraba, eritema, e, inflamaci√≥n, palpebral, y, conjuntival,, siendo, el, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>283</td>\n","      <td>[Var√≥n, de, 72, a√±os, diagnosticado, de, glaucoma, primario, de, √°ngulo, abierto, e, intervenido, de, trabeculectom√≠a, de, ambos, ojos, en, febrero, de, 2001, con, buen, control, tensional., Un, a√±o, m√°s, tarde, el, paciente, fue, intervenido, de, cataratas, mediante, facoemulsificaci√≥n, m√°s, implante, de, lente, intraocular, de, c√°mara, posterior, que, curs√≥, sin, complicaciones,, conservando, √≠ntegra, la, c√°psula, posterior, y, logrando, una, agudeza, visual, (AV), de, 0,6, en, OD, y, de, 0,5, en, OI., Dos, a√±os, despu√©s, de, la, cirug√≠a, filtrante,, el, campo, visual, mostr√≥, progresi√≥n, en, su, OD, y, una, presi√≥n, intraocular, de, 23, mmHg, por, lo, que, se, instaur√≥, tratamiento, con, travoprost, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, B-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>56</td>\n","      <td>[Paciente, de, 56, a√±os, remitido, a, nuestro, servicio, por, hallazgo, incidental, de, masa, renal, de, 5, cm, de, di√°metro, m√°ximo,, mesorrenal, izquierda, en, la, ecograf√≠a, durante, el, estudio, de, cuadro, de, crisis, renoureteral, del, mismo, lado., Como, √∫nico, antecedente, el, paciente, padece, hiperuricemia,, y, no, refiere, haber, presentado, episodios, de, hematuria., En, el, centro, donde, se, diagnostic√≥, se, realiz√≥, estudio, de, extensi√≥n, con, radiograf√≠a, de, t√≥rax,, hemograma,, bioqu√≠mica, y, tomograf√≠a, computerizada, abdomino-p√©lvica,, donde, se, evidenci√≥, trombo, tumoral, que, se, extend√≠a, por, la, vena, renal, hasta, la, vena, cava, retrohep√°tica., Ante, este, caso, se, decidi√≥, en, el, centro, emisor,, colocar, filtro, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, B-PROCEDIMIENTO, B-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>231</td>\n","      <td>[Paciente, de, 23, a√±os, diagnosticada, de, enfermedad, de, Crohn, de, localizaci√≥n, ileal., Inicialmente, presenta, un, patr√≥n, inflamatorio, que, evolucion√≥, a, estenosante, (crisis, suboclusivas, ocasionales), y, posteriormente, a, perforante,, desembocando, en, una, perforaci√≥n, abdominal, con, peritonitis, fecaloidea, que, motiv√≥, 3, intervenciones, quir√∫rgicas, durante, una, estancia, en, el, extranjero., Debido, a, las, numerosas, complicaciones, postoperatorias,, s√≠ndrome, de, intestino, corto, y, f√≠stula, enteroent√©rica, y, enterocut√°nea,, es, trasladada, a, nuestro, centro, hospitalario., Al, ingreso, presenta, febr√≠cula,, infecci√≥n, de, la, herida, con, dehiscencia, cut√°nea, y, desnutrici√≥n, severa., Es, portadora, de, una, ileostom√≠a, de, protecci√≥n,, fistulizaci√≥n, dirigida, a, nivel, de, anastomosis, ileo-c√≥lica, con, sonda, Petzer, y, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>634</td>\n","      <td>[Var√≥n, de, 43, a√±os,, previamente, sano, y, asintom√°tico,, que, acude, al, servicio, de, Cirug√≠a, Tor√°cica, al, objeto, de, completar, el, estudio, de, una, tumoraci√≥n, de, mediastino, medio, identificada, en, un, estudio, rutinario., En, el, estudio, faringo-esof√°gico,, tras, la, administraci√≥n, de, contraste, baritado,, se, aprecia, una, estenosis, de, unos, 3, cm, de, longitud, en, el, tercio, medio, del, es√≥fago, de, contornos, bien, definidos, y, que, reduce, la, luz, esof√°gica, en, un, 50%., Estos, hallazgos, son, compatibles, con, un, proceso, compresivo, extr√≠nseco., Se, efect√∫a, videotoracoscopia, derecha, por, tres, v√≠as., Se, identifica, la, presencia, de, una, tumoraci√≥n, en, mediastino, medio, a, nivel, de, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>350</td>\n","      <td>[Reci√©n, nacida, a, t√©rmino, que, fue, enviada, para, valoraci√≥n, oftalmol√≥gica, a, los, 20, d√≠as, de, vida, por, la, aparici√≥n, de, nistagmo, ocasional., Su, madre,, sin, antecedentes, de, importancia, durante, el, embarazo,, hab√≠a, sido, operada, de, glaucoma, a, los, 20, a√±os, de, edad, con, trabeculectom√≠a, bilateral, y, cirug√≠a, reconstructiva, de, sindactilia, de, manos., En, el, examen, oftalmol√≥gico, se, observaban, microc√≥rneas, con, aspecto, discretamente, velado,, nistagmo, horizontal, ocasional,, tono, ocular, digital, aumentado, en, forma, bilateral, y, fondo, de, ojo, (FO), con, papilas, de, caracter√≠sticas, conservadas;, y, el, examen, f√≠sico, general, revelaba, una, pir√°mide, nasal, estrecha, con, narinas, estrechas, y, alas, nasales, finas,, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>631</td>\n","      <td>[Se, presenta, el, caso, de, una, mujer, de, 27, a√±os, de, nacionalidad, china,, que, no, comprend√≠a, castellano,, sin, alergias, medicamentosas, conocidas,, ni, antecedentes, m√©dico-quir√∫rgicos, de, inter√©s, y, correctamente, vacunada, durante, la, infancia, en, su, pa√≠s, de, origen., La, paciente, acudi√≥, por, primera, vez, a, urgencias, del, centro, de, salud, por, una, reacci√≥n, urticariforme, pruriginosa, de, veinticuatro, horas, de, evoluci√≥n., En, esta, primera, consulta, se, le, paut√≥, un, antihistam√≠nico, intramuscular, y, corticoide, de, liberaci√≥n, retardada, siendo, diagnosticada, de, urticaria., Un, d√≠a, m√°s, tarde, la, paciente, acude, de, nuevo, a, urgencias, por, presentar, aumento, de, las, lesiones,, refiriendo, intenso, picor, en, cara,, ...]</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, O, B-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, I-PROCEDIMIENTO, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["show_random_elements(datasets[\"train\"])"]},{"cell_type":"markdown","metadata":{"id":"n9qywopnIrJH"},"source":["## Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"YVx71GdAIrJH"},"source":["Before we can feed those texts to our model, we need to preprocess them. This is done by a ü§ó Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n","\n","To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n","\n","- we get a tokenizer that corresponds to the model architecture we want to use,\n","- we download the vocabulary used when pretraining this specific checkpoint.\n","\n","That vocabulary will be cached, so it's not downloaded again the next time we run the cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXNLu_-nIrJI","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["dbac195c1c384c60b26dc9693090ef57","4e657f4999b94533b6dbc11abba86452","4fbfb811f4da4f6488df676438ffc248","5d0f76cf211c4d13925ade8dcbd06bdd","805b8eef98344e01ae4712c39a44113e","02a392714e3b4991b49bcac28fdb12c8","35f798b0afdc4cfaa2eefe152e7cdb69","2f37722b6a154a49a853e743cf687677","a47a52485ad34e6b9db601300ed4968f","39bf7a98e9e840feb33748272ad7ca8c","176a3789eefd401687ea3081ee197e68","630445609da443548e1276d835cf841b","4b35fb4d53eb44e8aa30c1a67e6b4407","c66e77a8c0524465aeb0b65c2d28d2f4","f1b95e5f07954045bbd04b5d410daccb","ddb28e2f84124da89ed2569cf3adf26a","a211a6b75f6f41b9b883568bff4b09b5","15b8193f8a404361863c9d8afbbd6d7e","a7a569f3930544f2a437c7a8d796db26","51b2781dcfe34674880d66011c769ca9","c4dea92874b34e1fbc04d52028ebe4a7","e7dfd4268b3f4d0594718eadf9fcf769","5d13363950b941d684f99802de327956","b6fbb42216e240ada821fe1925c9814b","ff10d14b10cf4cb88d41f0af77fcd550","f68e8f47cc4f44a59613696b1cecc158","cf77da9674c24bd09536cd680bc6e893","52ed8bbb17364697bfa357e60d7dc020","0282fd08a7b446f4be1eaafec16e420a","fcdca179078e44968332a2d095bc626c","b127b079902148eba901f20b91543f1d","3e026ce703314540add44b7541ae5d49","9230e14f35244078972aa5b9734abaaf","14949128ad9445d4b294934b7a626126","6064b7090c3e4802b4d91114d82ed7f0","f533d6833ae341f7af9eb3f1a4e90d63","c6ebdfd0116143f791c132b385f4388b","2699cb4ddd544bec91cf0532fdd39d15","732de4ac715d41938d96ea085babe5ae","1c8ddcd9901b48e883b82cc770e43008","2d6b218698b943598fa4cc3011b08dbf","f4e5dc6f80144bdeba80166c91d1c95e","cf54340bb9c74249b9303193fe328d75","6dc108218dd04e728881ef661444ad83","b3686e2782e0498098a78c62391d8751","444b489a5d364e8fbb1f42dd04ea2039","a44c5b981e4546009299aff15cfc3763","05d6f2b031d0413188a0826a69c47b20","75b973d98bc44591819071c8c157eb3a","ff78892f8fef4bf8afafefdbbf522b08","a73776031d69470e96db321f5339b424","f3900b1d6d25493da2665f1c5609e5d1","78462ab0fefe4138b9bfa2d06e77209d","38acba6a190b474e975f8d4d5f5e7cb4","a69223e302e84799b0bfab3efb9b0772"]},"executionInfo":{"status":"ok","timestamp":1681483315689,"user_tz":-180,"elapsed":4444,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"6e40f929-2465-44b9-8fe1-f008a42cbab5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbac195c1c384c60b26dc9693090ef57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"630445609da443548e1276d835cf841b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)olve/main/vocab.json:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d13363950b941d684f99802de327956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)olve/main/merges.txt:   0%|          | 0.00/540k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14949128ad9445d4b294934b7a626126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3686e2782e0498098a78c62391d8751"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"Vl6IidfdIrJK"},"source":["The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ü§ó Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2-avFvz0U3A"},"outputs":[],"source":["import transformers\n","assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"]},{"cell_type":"markdown","metadata":{"id":"IP6dB05A0U3A"},"source":["You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."]},{"cell_type":"markdown","metadata":{"id":"rowT4iCLIrJK"},"source":["You can directly call this tokenizer on one sentence:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5hBlsrHIrJL","outputId":"9dd491da-684c-4f98-8dc0-c4845d712cf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681483315690,"user_tz":-180,"elapsed":19,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 428, 4354, 15, 8237, 1658, 14719, 1308, 3507, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":18}],"source":["tokenizer(\"Hello, this is one sentence!\")"]},{"cell_type":"markdown","metadata":{"id":"eVx5rvih0U3A"},"source":["Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n","\n","If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument `is_split_into_words=True`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ls7hqu9Y0U3B","executionInfo":{"status":"ok","timestamp":1681483315690,"user_tz":-180,"elapsed":16,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"0528534d-553f-461d-c201-6293fe148f6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 428, 4354, 50288, 8237, 1658, 14719, 1308, 3507, 274, 586, 401, 12250, 14478, 30953, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":19}],"source":["tokenizer([\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"], is_split_into_words=True)"]},{"cell_type":"markdown","metadata":{"id":"TVqfrFz_0U3B"},"source":["Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbbcfUE60U3B","executionInfo":{"status":"ok","timestamp":1681483315690,"user_tz":-180,"elapsed":14,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"6304f525-daec-40fa-d625-42b8b649a421"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Var√≥n', 'de', '36', 'a√±os,', 'sin', 'antecedentes', 'de', 'inter√©s,', 'que', 'fue', 'estudiado', 'en', 'la', 'consulta', 'de', 'medicina', 'interna', 'por', 'presentar', 'masa', 'inguinoescrotal', 'izquierda', 'dolorosa', 'a', 'la', 'palpaci√≥n', 'de', 'dos', 'meses', 'de', 'evoluci√≥n,', 'sin', 'p√©rdida', 'de', 'peso', 'ni', 's√≠ndrome', 'miccional.', 'A', 'la', 'exploraci√≥n,', 'los', 'testes', 'eran', 'de', 'tama√±o', 'y', 'consistencia', 'normales,', 'con', 'un', 'cord√≥n', 'esperm√°tico', 'izquierdo', 'indurado', 'y', 'muy', 'doloroso.', 'La', 'ecograf√≠a', 'testicular', 'fue', 'normal.', 'La', 'CT', 'de', 'abdomen-pelvis', 'revel√≥', 'masa', 'de', '6', 'x', '3', 'cent√≠metros', 'en', 'el', 'trayecto', 'del', 'cord√≥n', 'esperm√°tico', 'izquierdo', 'sin', 'objetivarse', 'im√°genes', 'de', 'afectaci√≥n', 'retroperitoneal.', 'Con', 'el', 'diagn√≥stico', 'de', 'tumor', 'paratesticular', 'izquierdo', 'fue', 'intervenido,', 'encontr√°ndose', 'una', 'masa', 'en', 'cord√≥n', 'esperm√°tico', 'y', 'realiz√°ndose', 'biopsia', 'intraoperatoria', 'informada', 'como', 'proliferaci√≥n', 'neopl√°sica', 'de', 'aspecto', 'miofibrobl√°stico', 'no', 'linfomatosa,', 'por', 'lo', 'que', 'se', 'realiz√≥', 'orquiectom√≠a', 'radical', 'izquierda', 'reglada.', 'La', 'anatom√≠a', 'patol√≥gica', 'fue', 'de', 'rabdomiosarcoma', 'pleom√≥rfico', 'del', 'cord√≥n', 'esperm√°tico,', 'teste', 'y', 'epid√≠dimo', 'normales', 'y', 'negatividad', 'de', 'los', 'm√°rgenes', 'de', 'resecci√≥n.', 'Posteriormente', 'el', 'paciente', 'ha', 'recibido', 'varios', 'ciclos', 'de', 'quimioterapia', 'con', 'adriamicina', 'e', 'ifosfamida', '+', 'MESNA.', 'En', 'las', 'pruebas', 'de', 'imagen', 'de', 'control', 'a', 'los', 'cuatro', 'meses', 'de', 'la', 'cirug√≠a,', 'no', 'se', 'objetivan', 'recidivas', 'tumorales.']\n"]}],"source":["example = datasets[\"train\"][4]\n","print(example[\"tokens\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfvyqm5N0U3B","executionInfo":{"status":"ok","timestamp":1681483315690,"user_tz":-180,"elapsed":13,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"eaa0f995-5b75-4031-daf3-d0f7e93343f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>', 'ƒ†Var√É¬≥n', 'ƒ†de', 'ƒ†36', 'ƒ†a√É¬±os', ',', 'ƒ†sin', 'ƒ†antecedentes', 'ƒ†de', 'ƒ†inter√É¬©s', ',', 'ƒ†que', 'ƒ†fue', 'ƒ†estudiado', 'ƒ†en', 'ƒ†la', 'ƒ†consulta', 'ƒ†de', 'ƒ†medicina', 'ƒ†interna', 'ƒ†por', 'ƒ†presentar', 'ƒ†masa', 'ƒ†ingu', 'ino', 'esc', 'ro', 'tal', 'ƒ†izquierda', 'ƒ†dolorosa', 'ƒ†a', 'ƒ†la', 'ƒ†palpaci√É¬≥n', 'ƒ†de', 'ƒ†dos', 'ƒ†meses', 'ƒ†de', 'ƒ†evoluci√É¬≥n', ',', 'ƒ†sin', 'ƒ†p√É¬©rdida', 'ƒ†de', 'ƒ†peso', 'ƒ†ni', 'ƒ†s√É≈Éndrome', 'ƒ†miccional', '.', 'ƒ†A', 'ƒ†la', 'ƒ†exploraci√É¬≥n', ',', 'ƒ†los', 'ƒ†tes', 'tes', 'ƒ†eran', 'ƒ†de', 'ƒ†tama√É¬±o', 'ƒ†y', 'ƒ†consistencia', 'ƒ†normales', ',', 'ƒ†con', 'ƒ†un', 'ƒ†cord√É¬≥n', 'ƒ†esper', 'm√É¬°tico', 'ƒ†izquierdo', 'ƒ†ind', 'urado', 'ƒ†y', 'ƒ†muy', 'ƒ†doloroso', '.', 'ƒ†La', 'ƒ†ecograf√É≈Éa', 'ƒ†testicular', 'ƒ†fue', 'ƒ†normal', '.', 'ƒ†La', 'ƒ†CT', 'ƒ†de', 'ƒ†abdomen', '-', 'pel', 'vis', 'ƒ†revel√É¬≥', 'ƒ†masa', 'ƒ†de', 'ƒ†6', 'ƒ†x', 'ƒ†3', 'ƒ†cent√É≈Émetros', 'ƒ†en', 'ƒ†el', 'ƒ†trayecto', 'ƒ†del', 'ƒ†cord√É¬≥n', 'ƒ†esper', 'm√É¬°tico', 'ƒ†izquierdo', 'ƒ†sin', 'ƒ†objetivarse', 'ƒ†im√É¬°genes', 'ƒ†de', 'ƒ†afectaci√É¬≥n', 'ƒ†retroperitoneal', '.', 'ƒ†Con', 'ƒ†el', 'ƒ†diagn√É¬≥stico', 'ƒ†de', 'ƒ†tumor', 'ƒ†para', 'tes', 'ticular', 'ƒ†izquierdo', 'ƒ†fue', 'ƒ†intervenido', ',', 'ƒ†encontr√É¬°ndose', 'ƒ†una', 'ƒ†masa', 'ƒ†en', 'ƒ†cord√É¬≥n', 'ƒ†esper', 'm√É¬°tico', 'ƒ†y', 'ƒ†realiz√É¬°ndose', 'ƒ†biopsia', 'ƒ†intraoperatoria', 'ƒ†informada', 'ƒ†como', 'ƒ†proliferaci√É¬≥n', 'ƒ†neopl√É¬°sica', 'ƒ†de', 'ƒ†aspecto', 'ƒ†mio', 'fibro', 'bl', '√É¬°stico', 'ƒ†no', 'ƒ†linfoma', 'tosa', ',', 'ƒ†por', 'ƒ†lo', 'ƒ†que', 'ƒ†se', 'ƒ†realiz√É¬≥', 'ƒ†or', 'qui', 'ectom√É≈Éa', 'ƒ†radical', 'ƒ†izquierda', 'ƒ†reglada', '.', 'ƒ†La', 'ƒ†anatom√É≈Éa', 'ƒ†patol√É¬≥gica', 'ƒ†fue', 'ƒ†de', 'ƒ†rabdom', 'iosarcoma', 'ƒ†ple', 'om√É¬≥r', 'fico', 'ƒ†del', 'ƒ†cord√É¬≥n', 'ƒ†esper', 'm√É¬°tico', ',', 'ƒ†teste', 'ƒ†y', 'ƒ†epid', '√É≈Édimo', 'ƒ†normales', 'ƒ†y', 'ƒ†negatividad', 'ƒ†de', 'ƒ†los', 'ƒ†m√É¬°rgenes', 'ƒ†de', 'ƒ†resecci√É¬≥n', '.', 'ƒ†Posteriormente', 'ƒ†el', 'ƒ†paciente', 'ƒ†ha', 'ƒ†recibido', 'ƒ†varios', 'ƒ†ciclos', 'ƒ†de', 'ƒ†quimioterapia', 'ƒ†con', 'ƒ†ad', 'ri', 'amicina', 'ƒ†e', 'ƒ†i', 'fosfamida', 'ƒ†+', 'ƒ†MES', 'NA', '.', 'ƒ†En', 'ƒ†las', 'ƒ†pruebas', 'ƒ†de', 'ƒ†imagen', 'ƒ†de', 'ƒ†control', 'ƒ†a', 'ƒ†los', 'ƒ†cuatro', 'ƒ†meses', 'ƒ†de', 'ƒ†la', 'ƒ†cirug√É≈Éa', ',', 'ƒ†no', 'ƒ†se', 'ƒ†objetivan', 'ƒ†recidivas', 'ƒ†tumorales', '.', '</s>']\n"]}],"source":["tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","print(tokens)"]},{"cell_type":"markdown","metadata":{"id":"Lm7zVbAP0U3B"},"source":["Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n","\n","This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P69rKstL0U3C","executionInfo":{"status":"ok","timestamp":1681483315691,"user_tz":-180,"elapsed":11,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"73fe0ae7-b18e-4325-9bd9-202a0832b0e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(179, 227)"]},"metadata":{},"execution_count":22}],"source":["len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"])"]},{"cell_type":"markdown","metadata":{"id":"1jD1WPen0U3C"},"source":["Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOrVecS10U3C","executionInfo":{"status":"ok","timestamp":1681483315691,"user_tz":-180,"elapsed":9,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"7db0ae9e-ffad-42d9-f9f6-250f99ef107c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[None, 0, 1, 2, 3, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 20, 20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 37, 38, 39, 40, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 48, 49, 50, 51, 52, 52, 53, 54, 54, 55, 56, 57, 57, 58, 59, 60, 61, 62, 62, 63, 64, 65, 66, 66, 66, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 79, 80, 81, 82, 83, 84, 85, 86, 86, 87, 88, 89, 90, 91, 92, 92, 92, 93, 94, 95, 95, 96, 97, 98, 99, 100, 101, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 112, 112, 112, 113, 114, 114, 114, 115, 116, 117, 118, 119, 120, 120, 120, 121, 122, 123, 123, 124, 125, 126, 127, 128, 129, 129, 130, 130, 130, 131, 132, 133, 133, 133, 134, 135, 136, 136, 137, 138, 139, 140, 141, 142, 143, 144, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 155, 155, 156, 157, 157, 158, 159, 159, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 173, 174, 175, 176, 177, 178, 178, None]\n"]}],"source":["print(tokenized_input.word_ids())"]},{"cell_type":"markdown","metadata":{"id":"acUAUbIo0U3C"},"source":["As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_5XaY430U3C","executionInfo":{"status":"ok","timestamp":1681483315691,"user_tz":-180,"elapsed":8,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"1903c9ae-d45f-43dd-d80b-720d7b36cb98"},"outputs":[{"output_type":"stream","name":"stdout","text":["227 227\n"]}],"source":["word_ids = tokenized_input.word_ids()\n","aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n","print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"]},{"cell_type":"markdown","metadata":{"id":"MOoXbmUJ0U3D"},"source":["Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icsK2p7k0U3D"},"outputs":[],"source":["label_all_tokens = True"]},{"cell_type":"markdown","metadata":{"id":"2C0hcmp9IrJQ"},"source":["We're now ready to write the function that will preprocess our samples. We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model) and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vc0BSBLIIrJQ"},"outputs":[],"source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"{task}_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                label_ids.append(label[word_idx] if label_all_tokens else -100)\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"markdown","metadata":{"id":"0lm8ozrJIrJR"},"source":["This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-b70jh26IrJS","outputId":"3e886dfc-997e-444d-c913-59363bb0ecbc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681483316699,"user_tz":-180,"elapsed":1014,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[0, 3106, 262, 3210, 610, 262, 1172, 15, 1363, 687, 48257, 15, 526, 9321, 20472, 8463, 15, 300, 1752, 416, 3214, 5135, 29, 6208, 3560, 10430, 299, 7517, 17240, 290, 30318, 30, 15035, 262, 834, 262, 49493, 817, 11657, 288, 3428, 2550, 290, 4585, 16, 16624, 45765, 47039, 2729, 30, 6612, 24567, 981, 2974, 15, 17546, 277, 37330, 30, 288, 10132, 4540, 15, 14334, 262, 634, 10874, 759, 1010, 17, 438, 9074, 794, 3044, 3988, 344, 2966, 14005, 36994, 2857, 4324, 1240, 288, 363, 7234, 290, 2188, 26858, 10490, 9128, 4647, 15, 299, 44912, 3719, 17, 452, 284, 3904, 2469, 1752, 308, 1087, 1302, 1217, 15, 299, 5751, 290, 13399, 3719, 30, 14168, 11507, 6831, 299, 21426, 262, 5967, 2196, 414, 18, 3624, 17, 452, 284, 4464, 262, 3604, 4632, 284, 4320, 262, 588, 19511, 18, 2772, 290, 762, 16, 24, 7254, 18, 18382, 30, 2693, 262, 22519, 1599, 17, 21220, 1599, 30, 288, 284, 15850, 4632, 363, 10508, 262, 29781, 828, 18, 3877, 290, 12701, 262, 3789, 25, 828, 18, 3877, 30, 1719, 5351, 290, 2034, 1599, 17, 15945, 262, 362, 17, 1972, 6421, 18, 4364, 17, 839, 51125, 262, 3604, 563, 40163, 38362, 262, 20374, 17, 452, 284, 7805, 3424, 262, 5751, 313, 22292, 1794, 23161, 288, 6131, 5996, 290, 26152, 8811, 288, 2385, 22315, 5537, 290, 288, 12216, 17, 455, 6630, 35175, 5445, 262, 7362, 284, 4320, 262, 13067, 27662, 10666, 288, 7726, 1933, 15, 8660, 526, 1878, 299, 2177, 2120, 290, 5967, 299, 308, 1814, 262, 1467, 351, 17, 452, 284, 461, 3624, 313, 4226, 38361, 1240, 684, 2034, 4168, 15, 26152, 573, 28099, 2034, 2550, 290, 1300, 46492, 599, 790, 509, 411, 299, 4055, 262, 17795, 288, 297, 8207, 2232, 262, 2385, 1300, 46492, 15, 288, 1351, 269, 11299, 292, 907, 364, 34543, 29157, 17, 470, 43838, 3425, 7478, 363, 8660, 299, 2177, 2120, 15, 676, 10070, 38717, 27129, 288, 1351, 269, 8660, 262, 4015, 17, 455, 3900, 2874, 296, 1599, 17, 455, 8079, 20699, 19673, 284, 4320, 262, 5012, 47862, 43101, 15, 25593, 10359, 922, 39042, 299, 297, 2219, 30784, 262, 7022, 40656, 8879, 262, 8660, 17, 2], [0, 47522, 297, 990, 262, 308, 8276, 262, 3684, 610, 299, 898, 3664, 4288, 300, 2324, 6744, 4977, 35017, 262, 6399, 5305, 288, 297, 2447, 968, 290, 2389, 288, 284, 3403, 2092, 299, 20477, 350, 372, 348, 2983, 290, 43116, 2983, 12, 262, 2015, 329, 347, 5641, 1672, 16, 5085, 1257, 15, 344, 424, 300, 2839, 337, 2607, 262, 3599, 17, 7405, 262, 6811, 297, 2888, 6047, 288, 13308, 288, 363, 2689, 25997, 262, 45849, 5248, 15, 36341, 5316, 4221, 262, 45304, 526, 43260, 1297, 290, 17112, 262, 2565, 10779, 17, 2695, 318, 42196, 394, 22279, 2237, 1006, 262, 45849, 27050, 17, 2834, 297, 2680, 361, 754, 331, 2264, 9132, 299, 3214, 12226, 262, 1414, 3292, 269, 46075, 5248, 1752, 308, 2888, 262, 574, 488, 12157, 16606, 27739, 2550, 17, 455, 3904, 2469, 11405, 29, 403, 130, 107, 2015, 15, 21, 329, 30, 403, 17, 36, 29, 14931, 18, 2818, 4126, 30, 23247, 29, 11404, 4298, 17, 551, 2194, 5827, 15, 7665, 15, 14867, 1225, 15, 13569, 15, 299, 1087, 1302, 262, 5603, 277, 10169, 17, 452, 3152, 290, 4601, 373, 313, 26676, 13270, 15, 624, 30335, 624, 44029, 262, 8440, 20341, 15, 299, 17626, 16772, 11355, 21066, 17, 19894, 5454, 21702, 15, 526, 9226, 15, 1104, 606, 624, 28993, 17, 19894, 2552, 299, 9538, 331, 26168, 17963, 17, 7760, 7190, 15, 7410, 15, 526, 8303, 624, 15860, 17, 452, 284, 3904, 7997, 373, 313, 15008, 2418, 705, 33446, 624, 1116, 262, 14715, 17, 31402, 526, 16049, 624, 7977, 17, 33760, 14926, 4711, 290, 21066, 17, 452, 284, 3904, 35175, 313, 9231, 297, 40581, 1933, 7496, 262, 2775, 15, 373, 38107, 269, 1615, 15, 299, 3548, 262, 42176, 277, 28514, 5952, 269, 284, 4981, 15, 299, 2412, 331, 7424, 7998, 51945, 16, 423, 2421, 290, 922, 393, 7511, 320, 5078, 17, 666, 1116, 15515, 4384, 318, 399, 430, 412, 1139, 29, 21220, 29, 7016, 1314, 15, 26, 351, 18, 3877, 30, 7254, 1349, 17, 25, 1115, 18, 4844, 22, 350, 1054, 3054, 8685, 20766, 8754, 32928, 17, 913, 18, 1874, 22, 17, 30536, 29, 2015, 1874, 362, 130, 107, 2480, 17, 40391, 29, 49834, 8377, 10026, 47245, 1664, 15, 27, 4465, 17, 16387, 29, 4686, 18016, 828, 18, 3877, 30, 18327, 2884, 828, 18, 3877, 30, 9460, 762, 15, 28, 828, 18, 3877, 30, 7660, 11604, 1911, 18, 79, 30, 9111, 507, 15, 25, 1911, 18, 79, 30, 34164, 1577, 461, 18, 79, 30, 39951, 1672, 461, 18, 79, 30, 17277, 3527, 461, 18, 79, 30, 32541, 23536, 11604, 461, 18, 79, 30, 5192, 769, 15, 22, 828, 18, 3877, 17, 26438, 29, 22519, 1599, 17, 2834, 297, 2680, 313, 20561, 46655, 29, 3926, 361, 46075, 5248, 290, 47267, 6116, 361, 46075, 5248, 29, 9764, 262, 6403, 74, 1699, 33949, 30, 12111, 262, 1962, 304, 7632, 3310, 362, 18, 1183, 3565, 30, 46075, 2250, 1965, 27500, 3310, 362, 18, 6457, 715, 17, 839, 2282, 262, 2941, 38553, 350, 4277, 4166, 15, 16506, 2874, 15, 6251, 8180, 15, 30478, 43482, 12, 373, 19843, 2905, 4215, 15, 9546, 284, 16506, 18616, 15, 300, 2], [0, 551, 555, 262, 363, 1011, 262, 2884, 610, 23128, 269, 308, 754, 28323, 14172, 262, 967, 780, 363, 29941, 262, 24543, 344, 2269, 14577, 17, 2834, 297, 1190, 313, 15772, 363, 20165, 262, 634, 1874, 288, 284, 3389, 5977, 2550, 262, 284, 8660, 15, 982, 45735, 277, 1869, 11024, 389, 17, 455, 756, 373, 9754, 5659, 11588, 15, 416, 21930, 288, 297, 34533, 2917, 17, 551, 579, 2731, 363, 8124, 2211, 9529, 15, 288, 284, 883, 373, 313, 15772, 3921, 4211, 331, 6487, 9976, 2232, 17, 452, 297, 43838, 3425, 262, 284, 1858, 313, 9131, 262, 7362, 308, 8736, 262, 30812, 19903, 338, 290, 262, 4109, 27929, 15, 12106, 288, 284, 5612, 9008, 2550, 17, 839, 14609, 262, 1813, 290, 3604, 5381, 1789, 262, 318, 7951, 3719, 17, 551, 579, 2731, 363, 8079, 20699, 269, 284, 756, 15, 1058, 313, 29500, 284, 1876, 262, 363, 20165, 269, 2588, 262, 481, 77, 2009, 699, 869, 262, 4109, 27929, 290, 7384, 8404, 15, 288, 3389, 5977, 2550, 262, 8660, 15, 7570, 344, 5236, 290, 9301, 331, 44729, 29157, 25781, 17, 646, 297, 1263, 262, 48382, 262, 33960, 23057, 980, 9008, 313, 28091, 10359, 922, 39042, 262, 284, 20165, 17, 666, 15406, 14922, 411, 3959, 308, 3569, 36917, 15, 16727, 290, 39998, 15, 24099, 269, 318, 262, 308, 21426, 25039, 15, 299, 11689, 5183, 17, 470, 3487, 7752, 262, 284, 10359, 922, 39042, 3123, 7079, 344, 363, 11046, 262, 1509, 16383, 27809, 262, 26433, 24796, 15, 337, 2206, 300, 297, 8576, 15, 290, 8300, 277, 3773, 38439, 17, 720, 313, 6460, 724, 41737, 624, 11758, 2861, 17, 470, 754, 25102, 29547, 8886, 284, 23421, 361, 47963, 6020, 5933, 350, 2907, 39994, 15, 21782, 428, 31828, 3963, 2935, 288, 347, 1509, 9421, 827, 17, 334, 318, 1353, 1321, 262, 284, 10359, 922, 39042, 313, 2731, 8079, 20699, 262, 967, 15, 20763, 363, 7805, 33044, 11516, 573, 13266, 11208, 573, 297, 2482, 262, 10359, 3664, 15, 6831, 299, 43838, 2190, 43082, 831, 300, 313, 17092, 1366, 10359, 922, 39042, 262, 5187, 290, 262, 7644, 33960, 23057, 980, 32284, 290, 9498, 19861, 7695, 2917, 17, 2], [0, 6497, 262, 30403, 31001, 610, 526, 3214, 262, 2823, 300, 2839, 344, 29009, 15, 29711, 11588, 15, 28599, 290, 14005, 33014, 17, 452, 284, 4464, 262, 3604, 313, 14662, 1467, 16, 1979, 19511, 344, 2772, 17, 42014, 4552, 17, 551, 14843, 6630, 2874, 22776, 4893, 3055, 262, 1582, 44565, 262, 7685, 15, 15549, 299, 15988, 1345, 324, 15851, 2314, 17, 19312, 8079, 20699, 22776, 288, 3389, 5977, 2550, 15, 344, 2810, 262, 15625, 29157, 680, 5012, 2039, 573, 13266, 33923, 15, 299, 7384, 12736, 1599, 15, 4268, 269, 680, 13322, 385, 264, 17, 11148, 36575, 2629, 3055, 8485, 313, 34022, 636, 299, 334, 17, 44, 17, 49, 17, 40, 17, 797, 5457, 1120, 526, 300, 391, 745, 10883, 347, 2039, 15, 2203, 20344, 2353, 4487, 17, 551, 2149, 30064, 262, 4052, 2039, 43101, 15, 1793, 297, 3405, 30784, 297, 262, 33960, 23057, 980, 9008, 15, 38016, 284, 3055, 416, 481, 25431, 30081, 320, 262, 1509, 16383, 27809, 28251, 288, 45209, 7223, 590, 1519, 411, 299, 16306, 1104, 468, 290, 26433, 277, 3773, 38439, 526, 11758, 893, 15, 10152, 624, 1495, 3814, 7129, 4215, 17, 646, 297, 754, 25102, 29547, 313, 8886, 8184, 23421, 42086, 3501, 12675, 361, 47963, 262, 6020, 20215, 17, 452, 297, 2052, 21868, 337, 756, 373, 313, 427, 38620, 13321, 262, 7800, 2039, 17, 2], [0, 6497, 262, 3082, 610, 15, 526, 3214, 262, 2823, 15, 300, 802, 8507, 288, 284, 2371, 262, 2659, 4914, 344, 2966, 4258, 10499, 1045, 10680, 301, 554, 2639, 10682, 269, 284, 4981, 262, 680, 1321, 262, 1873, 15, 526, 2412, 262, 1814, 624, 2264, 11588, 17, 334, 284, 3904, 15, 318, 3551, 423, 3187, 262, 2775, 290, 11096, 3719, 15, 299, 308, 14389, 1914, 5931, 2729, 2761, 22712, 290, 740, 5952, 17, 455, 6630, 18616, 802, 1599, 17, 455, 12089, 262, 5751, 16, 12329, 777, 14979, 4258, 262, 693, 1082, 507, 16422, 288, 297, 17513, 331, 14389, 1914, 5931, 2729, 526, 46788, 4055, 262, 4623, 31216, 17, 646, 297, 1263, 262, 3146, 361, 423, 2421, 2729, 802, 15035, 15, 19190, 363, 4258, 288, 14389, 1914, 5931, 290, 25593, 6273, 33016, 20069, 416, 11046, 35284, 262, 3569, 3110, 19283, 480, 17005, 373, 11361, 6545, 15, 344, 424, 300, 313, 2731, 574, 488, 5810, 10335, 2639, 41039, 17, 455, 11248, 13002, 802, 262, 31382, 40199, 4164, 50491, 1682, 331, 14389, 1914, 5931, 15, 40581, 290, 7998, 51945, 3719, 290, 46219, 262, 318, 19403, 262, 10359, 17, 7218, 297, 756, 427, 5026, 2237, 8333, 262, 5791, 299, 611, 333, 15671, 277, 408, 24016, 2031, 31693, 4088, 17, 452, 347, 2282, 262, 2941, 262, 967, 269, 318, 2440, 1321, 262, 284, 1796, 15, 373, 313, 17386, 23932, 10629, 17, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"]},"metadata":{},"execution_count":27}],"source":["tokenize_and_align_labels(datasets['train'][:5])"]},{"cell_type":"markdown","metadata":{"id":"zS-6iXTkIrJT"},"source":["To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDtsaJeVIrJT","outputId":"0da65026-2ac1-4dd3-e041-3de2e061b9fd","colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["cd92c00ac8ce4f068f6fe361a20878ef","1bcbf92e427042ad912321ed02393efa","e39e4e08c990406d8048c0e4541d8ce0","1b9962845a60472e985830ab8a713c37","ad14a4fd30864350bf9c191761204190","53f06d5ba34642fea48fc71f3ecb3c92","1812611d52044586b61d1ef48dbafa54","f152316c8f604a27b71f1bef3c4d0634","e5ee5f26bf5d4a889e21effa78cec2a5","f224997f292344978a702e2736a35c26","3df7cd22149a40bcadc565e108d0edd2","e456611aa89f4931a143f90a2f02119a","cb0b3d6accd247b4a2630035f0ae8a69","fde38b6f57154d3384f6adbbe5fb6f7e","4c41ec1001764e8490e28595aa042bb8","4be62126abe441319fa820b93164b09b","fcab0f8713f84920ab721723a37f9876","bc532216e0214dcbbd46f5225f6429ff","e2b36985be8a44b38d0725ef8aa12c86","6532bbbf34cb4db8b3faf1b3c8a6f6a9","f91f6ebd1b7748b38a90f1ff805c5fc4","19fccd168199463d889d8acf554f9dbc"]},"executionInfo":{"status":"ok","timestamp":1681483317841,"user_tz":-180,"elapsed":1146,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/674 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd92c00ac8ce4f068f6fe361a20878ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/75 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e456611aa89f4931a143f90a2f02119a"}},"metadata":{}}],"source":["tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"voWiw8C7IrJV"},"source":["Even better, the results are automatically cached by the ü§ó Datasets library to avoid spending time on this step the next time you run your notebook. The ü§ó Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ü§ó Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n","\n","Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."]},{"cell_type":"markdown","metadata":{"id":"545PP3o8IrJV"},"source":["## Fine-tuning the model"]},{"cell_type":"markdown","metadata":{"id":"FBiW8UpKIrJW"},"source":["Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the `AutoModelForTokenClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TlqNaB8jIrJW","outputId":"83a37c0d-7cf3-423c-8b76-47e7184a5c1f","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["f77c33c16b504c4dae1ed187bef7b37a","d87ee78da1e4499981d807a4c4a042e0","7a4e665fd6404f379a259e19456cd848","a693b8b82d8a4cd895af76ad7302dfc0","c2bce8bb1130485abaff338c87ed473e","17e6171983cf4b97bcc3dc76e74d10d3","a22df66644314823ab7defcfd4852d09","e31f285ecc4449a7a3fddd2e67614aa3","35adcd4215c64ccbab8f59649cfc66e9","5bd6e4179493485c86eb6f3b201d66e0","38a7b124ce364c03b5ea0120b244e727"]},"executionInfo":{"status":"ok","timestamp":1681483352908,"user_tz":-180,"elapsed":35069,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/504M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77c33c16b504c4dae1ed187bef7b37a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es were not used when initializing RobertaForTokenClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"]},{"cell_type":"markdown","metadata":{"id":"CczA5lJlIrJX"},"source":["The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."]},{"cell_type":"markdown","metadata":{"id":"_N8urzhyIrJY"},"source":["To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bliy8zgjIrJY"},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    output_dir = f\"/content/drive/MyDrive/CLEF2023/{model_name}-finetuned-{task}\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_strategy = \"epoch\",\n","    #load_best_model_at_end=True,\n","    #metric_for_best_model=\"accuracy\",\n","    push_to_hub=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"km3pGVdTIrJc"},"source":["Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay.\n","\n","The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/bert-finetuned-ner\"` or `\"huggingface/bert-finetuned-ner\"`)."]},{"cell_type":"markdown","metadata":{"id":"ckvCH-7r0U3F"},"source":["Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCrXeprm0U3F"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"MbXOnncH0U3G"},"source":["The last thing to define for our `Trainer` is how to compute the metrics from the predictions. Here we will load the [`seqeval`](https://github.com/chakki-works/seqeval) metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["d2c6ab913bf3417fb1345221eb446b09","72aa83fceb234cc58f815a3689cf680b","326805f7cea94f98bb9cdb7aa24de303","c4ad56cdade24e63b0a264384605b610","df82720012b14562b44ca50bec5051fb","f80b29e966554229b874704cec198939","6fbf2f9573e342e3ae93f407c9cfba00","7105329c699148959f4b39e136a4a7f3","48f4bc445947434e8f77a76468e434fc","3b164371dc3b4ddbb93cddfe399300bc","4b692e92a5b2486394c6c6d86f90c1b3"]},"id":"q0ihrBQc0U3G","executionInfo":{"status":"ok","timestamp":1681483354920,"user_tz":-180,"elapsed":2029,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"c88c5e8b-b825-43c2-f9d0-2df982184433"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-32-e20ba34f8cc7>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"seqeval\")\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2c6ab913bf3417fb1345221eb446b09"}},"metadata":{}}],"source":["metric = load_metric(\"seqeval\")"]},{"cell_type":"markdown","metadata":{"id":"Npv3KD_H0U3G"},"source":["This metric takes list of labels for the predictions and references:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I76Fhrh40U3G","executionInfo":{"status":"ok","timestamp":1681483354922,"user_tz":-180,"elapsed":24,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"eb6e1473-7f90-41d5-9797-db13b3280991"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'PROCEDIMIENTO': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 9},\n"," 'overall_precision': 1.0,\n"," 'overall_recall': 1.0,\n"," 'overall_f1': 1.0,\n"," 'overall_accuracy': 1.0}"]},"metadata":{},"execution_count":33}],"source":["labels = [label_list[i] for i in example[f\"{task}_tags\"]]\n","metric.compute(predictions=[labels], references=[labels])"]},{"cell_type":"markdown","metadata":{"id":"7sZOdRlRIrJd"},"source":["So we will need to do a bit of post-processing on our predictions:\n","- select the predicted index (with the maximum logit) for each token\n","- convert it to its string label\n","- ignore everywhere we set a label of -100\n","\n","The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmvbnJ9JIrJd"},"outputs":[],"source":["import numpy as np\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"]},{"cell_type":"markdown","metadata":{"id":"rXuFTAzDIrJe"},"source":["Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n","\n","Then we just need to pass all of this along with our datasets to the `Trainer`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imY1oC3SIrJf"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{"id":"CdzABDVcIrJg"},"source":["We can now finetune our model by just calling the `train` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"1kT3ACGS0U3H","executionInfo":{"status":"ok","timestamp":1681483584893,"user_tz":-180,"elapsed":225167,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"52939da0-7ab2-47e3-fb32-bd20ece4d157"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [129/129 03:40, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.183960</td>\n","      <td>0.347973</td>\n","      <td>0.177281</td>\n","      <td>0.234892</td>\n","      <td>0.945956</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.137498</td>\n","      <td>0.424444</td>\n","      <td>0.328744</td>\n","      <td>0.370514</td>\n","      <td>0.952114</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.131894</td>\n","      <td>0.361795</td>\n","      <td>0.430293</td>\n","      <td>0.393082</td>\n","      <td>0.951839</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=129, training_loss=0.22315674419550932, metrics={'train_runtime': 224.9399, 'train_samples_per_second': 8.989, 'train_steps_per_second': 0.573, 'total_flos': 528345798128604.0, 'train_loss': 0.22315674419550932, 'epoch': 3.0})"]},"metadata":{},"execution_count":36}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"CKASz-2vIrJi"},"source":["The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOUcBkX8IrJi","outputId":"1d799347-c202-41ce-c2a1-160c84b5afac","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1681483588666,"user_tz":-180,"elapsed":3775,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.13189402222633362,\n"," 'eval_precision': 0.361794500723589,\n"," 'eval_recall': 0.43029259896729777,\n"," 'eval_f1': 0.39308176100628933,\n"," 'eval_accuracy': 0.9518387285424336,\n"," 'eval_runtime': 3.0689,\n"," 'eval_samples_per_second': 24.439,\n"," 'eval_steps_per_second': 1.629,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":37}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"NpnJ1fJQ0U3H"},"source":["To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"id":"4acRPb-Z0U3H","executionInfo":{"status":"ok","timestamp":1681483592120,"user_tz":-180,"elapsed":3463,"user":{"displayName":"Sylvia Vassileva","userId":"18356117093765644087"}},"outputId":"f52055ff-8cff-4ac5-a110-1ea1bde42a75"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'PROCEDIMIENTO': {'precision': 0.361794500723589,\n","  'recall': 0.43029259896729777,\n","  'f1': 0.39308176100628933,\n","  'number': 581},\n"," 'overall_precision': 0.361794500723589,\n"," 'overall_recall': 0.43029259896729777,\n"," 'overall_f1': 0.39308176100628933,\n"," 'overall_accuracy': 0.9518387285424336}"]},"metadata":{},"execution_count":38}],"source":["predictions, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n","predictions = np.argmax(predictions, axis=2)\n","\n","# Remove ignored index (special tokens)\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","\n","results = metric.compute(predictions=true_predictions, references=true_labels)\n","results"]},{"cell_type":"markdown","metadata":{"id":"RS7tNiCy0U3I"},"source":["You can now upload the result of the training to the Hub, just execute this instruction:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELmF4yqI0U3I"},"outputs":[],"source":["#trainer.push_to_hub()"]},{"cell_type":"markdown","metadata":{"id":"SR3mPFVF0U3I"},"source":["You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n","\n","```python\n","from transformers import AutoModelForTokenClassification\n","\n","model = AutoModelForTokenClassification.from_pretrained(\"sgugger/my-awesome-model\")\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohLrCgrh0U3I"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"78f159aaca6948d69754a235073a72b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8af60fc134747379018da09a1b664ee","IPY_MODEL_f086696d3ee6486f824bb618c7133056","IPY_MODEL_194854063f9c453589869749e6c2f570"],"layout":"IPY_MODEL_775d99d923fa4cef8f0d6626d93c6ca1"}},"e8af60fc134747379018da09a1b664ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81431a2622504d76b009f64b1b3a1bf7","placeholder":"‚Äã","style":"IPY_MODEL_77abf11b516744db880dd1af91146886","value":"Generating train split: "}},"f086696d3ee6486f824bb618c7133056":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb66d823f24d45f6a9ac521783c3423d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e863f49462174ae4a042c9106edf6a98","value":1}},"194854063f9c453589869749e6c2f570":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9479b978329462aab901b7ca2047236","placeholder":"‚Äã","style":"IPY_MODEL_cf54f2e3b5f341dc9d0322d222552749","value":" 699/0 [00:01&lt;00:00, 620.68 examples/s]"}},"775d99d923fa4cef8f0d6626d93c6ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"81431a2622504d76b009f64b1b3a1bf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77abf11b516744db880dd1af91146886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb66d823f24d45f6a9ac521783c3423d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e863f49462174ae4a042c9106edf6a98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9479b978329462aab901b7ca2047236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf54f2e3b5f341dc9d0322d222552749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9416fd8213e4806821bc9affd7bd3a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_217b509357aa4bba8a61760c0fa0a64a","IPY_MODEL_f338acf4e6be4e0d8664c62a95c7013f","IPY_MODEL_822bbc33d7ba407eb398c3274f7f6707"],"layout":"IPY_MODEL_3e3eb094581b437895ed6edd4f32059f"}},"217b509357aa4bba8a61760c0fa0a64a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8851ad367b84f47911e9cf2507a26ec","placeholder":"‚Äã","style":"IPY_MODEL_95ec96bedbf94a28997193b56c73750e","value":"100%"}},"f338acf4e6be4e0d8664c62a95c7013f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1a8e0e98044f9fa135bff1f014f395","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d02f3d852ae24b08ae15040e4417de5a","value":2}},"822bbc33d7ba407eb398c3274f7f6707":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05e5837ee6f54b1da2fd1438efd78269","placeholder":"‚Äã","style":"IPY_MODEL_b2ed932423324294af65b6ac7d0372e8","value":" 2/2 [00:00&lt;00:00, 95.88it/s]"}},"3e3eb094581b437895ed6edd4f32059f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8851ad367b84f47911e9cf2507a26ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ec96bedbf94a28997193b56c73750e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f1a8e0e98044f9fa135bff1f014f395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d02f3d852ae24b08ae15040e4417de5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05e5837ee6f54b1da2fd1438efd78269":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ed932423324294af65b6ac7d0372e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbac195c1c384c60b26dc9693090ef57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e657f4999b94533b6dbc11abba86452","IPY_MODEL_4fbfb811f4da4f6488df676438ffc248","IPY_MODEL_5d0f76cf211c4d13925ade8dcbd06bdd"],"layout":"IPY_MODEL_805b8eef98344e01ae4712c39a44113e"}},"4e657f4999b94533b6dbc11abba86452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02a392714e3b4991b49bcac28fdb12c8","placeholder":"‚Äã","style":"IPY_MODEL_35f798b0afdc4cfaa2eefe152e7cdb69","value":"Downloading (‚Ä¶)okenizer_config.json: 100%"}},"4fbfb811f4da4f6488df676438ffc248":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f37722b6a154a49a853e743cf687677","max":1270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a47a52485ad34e6b9db601300ed4968f","value":1270}},"5d0f76cf211c4d13925ade8dcbd06bdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39bf7a98e9e840feb33748272ad7ca8c","placeholder":"‚Äã","style":"IPY_MODEL_176a3789eefd401687ea3081ee197e68","value":" 1.27k/1.27k [00:00&lt;00:00, 56.1kB/s]"}},"805b8eef98344e01ae4712c39a44113e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02a392714e3b4991b49bcac28fdb12c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f798b0afdc4cfaa2eefe152e7cdb69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f37722b6a154a49a853e743cf687677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a47a52485ad34e6b9db601300ed4968f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39bf7a98e9e840feb33748272ad7ca8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"176a3789eefd401687ea3081ee197e68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"630445609da443548e1276d835cf841b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b35fb4d53eb44e8aa30c1a67e6b4407","IPY_MODEL_c66e77a8c0524465aeb0b65c2d28d2f4","IPY_MODEL_f1b95e5f07954045bbd04b5d410daccb"],"layout":"IPY_MODEL_ddb28e2f84124da89ed2569cf3adf26a"}},"4b35fb4d53eb44e8aa30c1a67e6b4407":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a211a6b75f6f41b9b883568bff4b09b5","placeholder":"‚Äã","style":"IPY_MODEL_15b8193f8a404361863c9d8afbbd6d7e","value":"Downloading (‚Ä¶)lve/main/config.json: 100%"}},"c66e77a8c0524465aeb0b65c2d28d2f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7a569f3930544f2a437c7a8d796db26","max":613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_51b2781dcfe34674880d66011c769ca9","value":613}},"f1b95e5f07954045bbd04b5d410daccb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4dea92874b34e1fbc04d52028ebe4a7","placeholder":"‚Äã","style":"IPY_MODEL_e7dfd4268b3f4d0594718eadf9fcf769","value":" 613/613 [00:00&lt;00:00, 29.9kB/s]"}},"ddb28e2f84124da89ed2569cf3adf26a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a211a6b75f6f41b9b883568bff4b09b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15b8193f8a404361863c9d8afbbd6d7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7a569f3930544f2a437c7a8d796db26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51b2781dcfe34674880d66011c769ca9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4dea92874b34e1fbc04d52028ebe4a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7dfd4268b3f4d0594718eadf9fcf769":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d13363950b941d684f99802de327956":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6fbb42216e240ada821fe1925c9814b","IPY_MODEL_ff10d14b10cf4cb88d41f0af77fcd550","IPY_MODEL_f68e8f47cc4f44a59613696b1cecc158"],"layout":"IPY_MODEL_cf77da9674c24bd09536cd680bc6e893"}},"b6fbb42216e240ada821fe1925c9814b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52ed8bbb17364697bfa357e60d7dc020","placeholder":"‚Äã","style":"IPY_MODEL_0282fd08a7b446f4be1eaafec16e420a","value":"Downloading (‚Ä¶)olve/main/vocab.json: 100%"}},"ff10d14b10cf4cb88d41f0af77fcd550":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcdca179078e44968332a2d095bc626c","max":1216538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b127b079902148eba901f20b91543f1d","value":1216538}},"f68e8f47cc4f44a59613696b1cecc158":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e026ce703314540add44b7541ae5d49","placeholder":"‚Äã","style":"IPY_MODEL_9230e14f35244078972aa5b9734abaaf","value":" 1.22M/1.22M [00:00&lt;00:00, 5.59MB/s]"}},"cf77da9674c24bd09536cd680bc6e893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ed8bbb17364697bfa357e60d7dc020":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0282fd08a7b446f4be1eaafec16e420a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcdca179078e44968332a2d095bc626c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b127b079902148eba901f20b91543f1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e026ce703314540add44b7541ae5d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9230e14f35244078972aa5b9734abaaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14949128ad9445d4b294934b7a626126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6064b7090c3e4802b4d91114d82ed7f0","IPY_MODEL_f533d6833ae341f7af9eb3f1a4e90d63","IPY_MODEL_c6ebdfd0116143f791c132b385f4388b"],"layout":"IPY_MODEL_2699cb4ddd544bec91cf0532fdd39d15"}},"6064b7090c3e4802b4d91114d82ed7f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_732de4ac715d41938d96ea085babe5ae","placeholder":"‚Äã","style":"IPY_MODEL_1c8ddcd9901b48e883b82cc770e43008","value":"Downloading (‚Ä¶)olve/main/merges.txt: 100%"}},"f533d6833ae341f7af9eb3f1a4e90d63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d6b218698b943598fa4cc3011b08dbf","max":540221,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4e5dc6f80144bdeba80166c91d1c95e","value":540221}},"c6ebdfd0116143f791c132b385f4388b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf54340bb9c74249b9303193fe328d75","placeholder":"‚Äã","style":"IPY_MODEL_6dc108218dd04e728881ef661444ad83","value":" 540k/540k [00:00&lt;00:00, 3.70MB/s]"}},"2699cb4ddd544bec91cf0532fdd39d15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"732de4ac715d41938d96ea085babe5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c8ddcd9901b48e883b82cc770e43008":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d6b218698b943598fa4cc3011b08dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4e5dc6f80144bdeba80166c91d1c95e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf54340bb9c74249b9303193fe328d75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc108218dd04e728881ef661444ad83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3686e2782e0498098a78c62391d8751":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_444b489a5d364e8fbb1f42dd04ea2039","IPY_MODEL_a44c5b981e4546009299aff15cfc3763","IPY_MODEL_05d6f2b031d0413188a0826a69c47b20"],"layout":"IPY_MODEL_75b973d98bc44591819071c8c157eb3a"}},"444b489a5d364e8fbb1f42dd04ea2039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff78892f8fef4bf8afafefdbbf522b08","placeholder":"‚Äã","style":"IPY_MODEL_a73776031d69470e96db321f5339b424","value":"Downloading (‚Ä¶)cial_tokens_map.json: 100%"}},"a44c5b981e4546009299aff15cfc3763":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3900b1d6d25493da2665f1c5609e5d1","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78462ab0fefe4138b9bfa2d06e77209d","value":772}},"05d6f2b031d0413188a0826a69c47b20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38acba6a190b474e975f8d4d5f5e7cb4","placeholder":"‚Äã","style":"IPY_MODEL_a69223e302e84799b0bfab3efb9b0772","value":" 772/772 [00:00&lt;00:00, 49.2kB/s]"}},"75b973d98bc44591819071c8c157eb3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff78892f8fef4bf8afafefdbbf522b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73776031d69470e96db321f5339b424":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3900b1d6d25493da2665f1c5609e5d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78462ab0fefe4138b9bfa2d06e77209d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38acba6a190b474e975f8d4d5f5e7cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a69223e302e84799b0bfab3efb9b0772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd92c00ac8ce4f068f6fe361a20878ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bcbf92e427042ad912321ed02393efa","IPY_MODEL_e39e4e08c990406d8048c0e4541d8ce0","IPY_MODEL_1b9962845a60472e985830ab8a713c37"],"layout":"IPY_MODEL_ad14a4fd30864350bf9c191761204190"}},"1bcbf92e427042ad912321ed02393efa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f06d5ba34642fea48fc71f3ecb3c92","placeholder":"‚Äã","style":"IPY_MODEL_1812611d52044586b61d1ef48dbafa54","value":"Map: 100%"}},"e39e4e08c990406d8048c0e4541d8ce0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f152316c8f604a27b71f1bef3c4d0634","max":674,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5ee5f26bf5d4a889e21effa78cec2a5","value":674}},"1b9962845a60472e985830ab8a713c37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f224997f292344978a702e2736a35c26","placeholder":"‚Äã","style":"IPY_MODEL_3df7cd22149a40bcadc565e108d0edd2","value":" 674/674 [00:01&lt;00:00, 435.84 examples/s]"}},"ad14a4fd30864350bf9c191761204190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"53f06d5ba34642fea48fc71f3ecb3c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1812611d52044586b61d1ef48dbafa54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f152316c8f604a27b71f1bef3c4d0634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5ee5f26bf5d4a889e21effa78cec2a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f224997f292344978a702e2736a35c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3df7cd22149a40bcadc565e108d0edd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e456611aa89f4931a143f90a2f02119a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb0b3d6accd247b4a2630035f0ae8a69","IPY_MODEL_fde38b6f57154d3384f6adbbe5fb6f7e","IPY_MODEL_4c41ec1001764e8490e28595aa042bb8"],"layout":"IPY_MODEL_4be62126abe441319fa820b93164b09b"}},"cb0b3d6accd247b4a2630035f0ae8a69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcab0f8713f84920ab721723a37f9876","placeholder":"‚Äã","style":"IPY_MODEL_bc532216e0214dcbbd46f5225f6429ff","value":"Map: 100%"}},"fde38b6f57154d3384f6adbbe5fb6f7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2b36985be8a44b38d0725ef8aa12c86","max":75,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6532bbbf34cb4db8b3faf1b3c8a6f6a9","value":75}},"4c41ec1001764e8490e28595aa042bb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f91f6ebd1b7748b38a90f1ff805c5fc4","placeholder":"‚Äã","style":"IPY_MODEL_19fccd168199463d889d8acf554f9dbc","value":" 75/75 [00:00&lt;00:00, 384.57 examples/s]"}},"4be62126abe441319fa820b93164b09b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"fcab0f8713f84920ab721723a37f9876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc532216e0214dcbbd46f5225f6429ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2b36985be8a44b38d0725ef8aa12c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6532bbbf34cb4db8b3faf1b3c8a6f6a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f91f6ebd1b7748b38a90f1ff805c5fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19fccd168199463d889d8acf554f9dbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f77c33c16b504c4dae1ed187bef7b37a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d87ee78da1e4499981d807a4c4a042e0","IPY_MODEL_7a4e665fd6404f379a259e19456cd848","IPY_MODEL_a693b8b82d8a4cd895af76ad7302dfc0"],"layout":"IPY_MODEL_c2bce8bb1130485abaff338c87ed473e"}},"d87ee78da1e4499981d807a4c4a042e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17e6171983cf4b97bcc3dc76e74d10d3","placeholder":"‚Äã","style":"IPY_MODEL_a22df66644314823ab7defcfd4852d09","value":"Downloading pytorch_model.bin: 100%"}},"7a4e665fd6404f379a259e19456cd848":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e31f285ecc4449a7a3fddd2e67614aa3","max":504420627,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35adcd4215c64ccbab8f59649cfc66e9","value":504420627}},"a693b8b82d8a4cd895af76ad7302dfc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd6e4179493485c86eb6f3b201d66e0","placeholder":"‚Äã","style":"IPY_MODEL_38a7b124ce364c03b5ea0120b244e727","value":" 504M/504M [00:23&lt;00:00, 22.5MB/s]"}},"c2bce8bb1130485abaff338c87ed473e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e6171983cf4b97bcc3dc76e74d10d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22df66644314823ab7defcfd4852d09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e31f285ecc4449a7a3fddd2e67614aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35adcd4215c64ccbab8f59649cfc66e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bd6e4179493485c86eb6f3b201d66e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38a7b124ce364c03b5ea0120b244e727":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2c6ab913bf3417fb1345221eb446b09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72aa83fceb234cc58f815a3689cf680b","IPY_MODEL_326805f7cea94f98bb9cdb7aa24de303","IPY_MODEL_c4ad56cdade24e63b0a264384605b610"],"layout":"IPY_MODEL_df82720012b14562b44ca50bec5051fb"}},"72aa83fceb234cc58f815a3689cf680b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80b29e966554229b874704cec198939","placeholder":"‚Äã","style":"IPY_MODEL_6fbf2f9573e342e3ae93f407c9cfba00","value":"Downloading builder script: "}},"326805f7cea94f98bb9cdb7aa24de303":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7105329c699148959f4b39e136a4a7f3","max":2472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48f4bc445947434e8f77a76468e434fc","value":2472}},"c4ad56cdade24e63b0a264384605b610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b164371dc3b4ddbb93cddfe399300bc","placeholder":"‚Äã","style":"IPY_MODEL_4b692e92a5b2486394c6c6d86f90c1b3","value":" 6.33k/? [00:00&lt;00:00, 416kB/s]"}},"df82720012b14562b44ca50bec5051fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f80b29e966554229b874704cec198939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fbf2f9573e342e3ae93f407c9cfba00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7105329c699148959f4b39e136a4a7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48f4bc445947434e8f77a76468e434fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b164371dc3b4ddbb93cddfe399300bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b692e92a5b2486394c6c6d86f90c1b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}